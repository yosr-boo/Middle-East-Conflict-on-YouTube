{"cells":[{"cell_type":"code","source":["pip install google-api-python-client"],"metadata":{"id":"faPRsolo4cPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96705,"status":"ok","timestamp":1736347343833,"user":{"displayName":"YOSR BOUHOULA","userId":"05524481636622740008"},"user_tz":-60},"id":"nwTcbS95NyyS","outputId":"b457a752-06f3-4ff8-cc96-d545763ecc45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from googleapiclient.discovery import build\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# API setup\n","API_KEY = '####'\n","YOUTUBE_API_SERVICE_NAME = 'youtube'\n","YOUTUBE_API_VERSION = 'v3'\n","\n","youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)"],"metadata":{"id":"An2t1b-U3O0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to fetch videos from a playlist\n","def get_videos_from_playlist(playlist_id, max_results=80):\n","    videos = []\n","    request = youtube.playlistItems().list(\n","        part=\"snippet\",\n","        playlistId=playlist_id,\n","        maxResults=max_results\n","    )\n","    response = request.execute()\n","\n","    for item in response.get('items', []):\n","        videos.append({\n","            'video_id': item['snippet']['resourceId']['videoId'],\n","            'title': item['snippet']['title'],\n","            'description': item['snippet']['description'],\n","            'published_at': item['snippet']['publishedAt']\n","        })\n","    return pd.DataFrame(videos)"],"metadata":{"id":"2eqt6Aj-3Pnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","\n","def filter_videos_by_date(videos_df, start_date):\n","    # Convert the publishedAt column to datetime format\n","    videos_df['published_at'] = pd.to_datetime(videos_df['published_at'], utc =True)\n","    # Filter videos within the date range\n","    filtered_videos = videos_df[\n","        (videos_df['published_at'] >= pd.Timestamp(start_date))\n","    ]\n","    return filtered_videos\n"],"metadata":{"id":"oHKWuteZ3Tey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to fetch comments for a video\n","def get_video_comments(video_id, max_results=300):\n","    comments = []\n","    try:\n","        request = youtube.commentThreads().list(\n","            part=\"snippet\",\n","            videoId=video_id,\n","            maxResults=max_results\n","        )\n","        response = request.execute()\n","\n","        for item in response.get('items', []):\n","            top_comment = item['snippet']['topLevelComment']['snippet']\n","            comments.append({\n","                'video_id': video_id,\n","                'comment_id': item['id'],\n","                'author': top_comment['authorDisplayName'],\n","                'comment': top_comment['textDisplay'],\n","                'likes': top_comment['likeCount'],\n","                'published_at': top_comment['publishedAt']\n","            })\n","    except Exception as e:\n","        print(f\"Error fetching comments for video {video_id}: {e}\")\n","    return pd.DataFrame(comments)"],"metadata":{"id":"mCa6lSWk3VaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to fetch replies for a comments on a video\n","def get_comment_replies(parent_comment_id, max_results=100):\n","\n","    replies_data = []\n","    try:\n","        # Request to fetch replies for the given parent comment\n","        request = youtube.comments().list(\n","            part=\"snippet\",\n","            parentId=parent_comment_id,\n","            maxResults=max_results,\n","            textFormat=\"plainText\"\n","        )\n","        response = request.execute()\n","\n","        # Process each reply\n","        for reply_item in response.get('items', []):\n","            reply = reply_item['snippet']\n","            replies_data.append({\n","                'comment_id': reply_item['id'],\n","                'author': reply['authorDisplayName'],\n","                'comment': reply['textDisplay'],\n","                'likes': reply['likeCount'],\n","                'published_at': reply['publishedAt']\n","            })\n","    except Exception as e:\n","        print(f\"Error fetching replies for comment {parent_comment_id}: {e}\")\n","    return pd.DataFrame(replies_data)\n"],"metadata":{"id":"qps6XajM3Y8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["playlist_ids = {\n","    'BBC_Playlist': 'PLS3XGZxi7cBUy1RAOyjaecHIM2z19fXO5',\n","    'Al_Jazeera_Playlist': 'PLzGHKb8i9vTzhLTxeWULNGg-ZYPA8CHhN'\n","}\n","start_date = pd.Timestamp(\"2023-10-07\", tz = \"UTC\")"],"metadata":{"id":"L1apRseM3bP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test Playlist ID\n","def verify_playlist(playlist_id):\n","    request = youtube.playlists().list(\n","        part=\"snippet\",\n","        id=playlist_id\n","    )\n","    response = request.execute()\n","    for item in response['items']:\n","        print(f\"Playlist Title: {item['snippet']['title']}\")\n","        print(f\"Channel: {item['snippet']['channelTitle']}\")\n","        print(f\"Description: {item['snippet']['description']}\")\n","        print()\n","\n"],"metadata":{"id":"ZNKJ6q183dHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Fetch videos from playlists\n","all_playlist_videos = pd.DataFrame()\n","for playlist_name, playlist_id in playlist_ids.items():\n","    print(f\"Fetching videos from playlist: {playlist_name}\")\n","    playlist_videos = get_videos_from_playlist(playlist_id)\n","    playlist_videos['playlist'] = playlist_name\n","    playlist_videos = filter_videos_by_date(playlist_videos, start_date)\n","    all_playlist_videos = pd.concat([all_playlist_videos, playlist_videos])\n","\n","# Fetch comments for all videos\n","all_comments = pd.DataFrame()\n","for video_id in all_playlist_videos['video_id']:\n","    print(f\"Fetching comments for video: {video_id}\")\n","    video_comments = get_video_comments(video_id)\n","    all_comments = pd.concat([all_comments, video_comments])\n","\n","# Fetch replies for all comments\n","all_replies = pd.DataFrame()\n","for comment_id in all_comments['comment_id']:\n","    print(f\"Fetching replies for comment: {comment_id}\")\n","    comment_replies = get_comment_replies(comment_id)\n","    all_replies = pd.concat([all_replies, comment_replies])\n","\n"],"metadata":{"id":"gLwlbI7r3g60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the datasets\n","comments_df = pd.read_csv('/content/drive/My Drive/Social Media Project/video_comments.csv')\n","playlist_df = pd.read_csv('/content/drive/My Drive/Social Media Project/playlist_videos.csv')\n","replies_df = pd.read_csv('/content/drive/My Drive/Social Media Project/comment_replies.csv')\n","\n","print(\"\\nComments Dataset:\")\n","print(comments_df.head())\n","print(\"\\nPlaylists Dataset:\")\n","print(playlist_df.head())\n","print(\"\\nReplies Dataset:\")\n","print(replies_df.head())"],"metadata":{"id":"sqsUefji41oz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_data = all_comments.merge(all_playlist_videos, on='video_id', how='left')"],"metadata":{"id":"mT3-QJ_15HsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_replies[\"comment_id\"] = all_replies[\"comment_id\"].str.split('.').str[0]"],"metadata":{"id":"9cohuek95Obl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_data = merged_data.merge(all_replies, on='comment_id', how='left')\n","final_data"],"metadata":{"id":"llCAJuAh5UsP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Rename and Rearrange the columns of the final dataset for a better representation\n","\n","final_data = final_data.rename(columns={'author_x': 'comment_author', 'comment_x': 'comment_text',\n","                     'likes_x': 'comment_likes', 'published_at_x':'comment_timestamp',\n","                     'published_at_y':'video_timestamp', 'author_y':'reply_author', 'comment_y': 'reply_text',\n","                     'likes_y': 'reply_likes', 'published_at': 'reply_timestamp'})\n","final_data = final_data[['video_id', 'video_timestamp', 'title', 'description', 'playlist',\n","             'comment_id', 'comment_author', 'comment_text', 'comment_likes',\n","             'comment_timestamp', 'reply_author', 'reply_text', 'reply_likes', 'reply_timestamp' ]]\n","final_data"],"metadata":{"id":"f5PFVh_T5cLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Save fimal dataset\n","final_data.to_csv('/content/drive/My Drive/Social Media Project/consolidated_data.csv', index=False)"],"metadata":{"id":"0m0oHN895fNU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPHPzHz2fWrjXQLSyqHqfKX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}